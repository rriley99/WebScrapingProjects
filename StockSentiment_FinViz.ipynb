{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\rriley\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen, Request\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import pandas as pd\n",
    "import datetime\n",
    "# NLTK VADER for sentiment analysis\n",
    "import nltk \n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import psycopg2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Discarding this since input will be a list of tickers'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Discarding this since input will be a list of tickers\"\"\" \n",
    "# # Get Tickers from database or yahoo_fin\n",
    "# conn = psycopg2.connect(\"dbname=StonksGoUp user=postgres host=localhost password=admin\")\n",
    "# cur = conn.cursor()\n",
    "\n",
    "# SQL_tickers = \"\"\"SELECT ticker FROM tickers ORDER BY ticker ASC\"\"\"\n",
    "# cur.execute(SQL_tickers)\n",
    "\n",
    "# #tickers = list([i[0] for i in cur.fetchall()])\n",
    "# print(tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 50)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<tokenize>\"\u001b[1;36m, line \u001b[1;32m50\u001b[0m\n\u001b[1;33m    def Get_Sentiment(parsed_news):\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "tickers = [\"SQ\",]\n",
    "def Get_News(tickers):\n",
    "    news_tables = {}\n",
    "\n",
    "    for ticker in tickers:\n",
    "        finviz_url = f'https://finviz.com/quote.ashx?t={ticker}'\n",
    "\n",
    "        req = Request(url=finviz_url,headers={'user-agent': 'my-app/0.0.1'}) \n",
    "        response = urlopen(req)    \n",
    "\n",
    "        # Read the contents of the file into 'html'\n",
    "        html = BeautifulSoup(response)\n",
    "\n",
    "        # Find 'news-table' in the Soup and load it into 'news_table'\n",
    "        news_table = html.find(id='news-table')\n",
    "\n",
    "        # Add the table to our dictionary\n",
    "        news_tables[ticker] = news_table\n",
    "    return news_tables\n",
    "\n",
    "def Parse_News(news_tables):\n",
    "    parsed_news = []\n",
    "\n",
    "    # Iterate through the news\n",
    "    for file_name, news_table in news_tables.items():\n",
    "        # Iterate through all tr tags in 'news_table'\n",
    "        for x in news_table.findAll('tr'):\n",
    "            # read the text from each tr tag into text\n",
    "            # get text from a only\n",
    "            text = x.a.get_text() \n",
    "            # splite text in the td tag into a list \n",
    "            date_scrape = x.td.text.split()\n",
    "            # if the length of 'date_scrape' is 1, load 'time' as the only element\n",
    "\n",
    "            if len(date_scrape) == 1:\n",
    "                time = date_scrape[0]\n",
    "\n",
    "            # else load 'date' as the 1st element and 'time' as the second    \n",
    "            else:\n",
    "                date = date_scrape[0]\n",
    "                time = date_scrape[1]\n",
    "            # Extract the ticker from the file name, get the string up to the 1st '_'  \n",
    "            ticker = file_name.split('_')[0]\n",
    "\n",
    "            # Append ticker, date, time and headline as a list to the 'parsed_news' list\n",
    "            parsed_news.append([ticker, date, time, text])\n",
    "    return parsed_news\n",
    "\n",
    "def Get_Sentiment(parsed_news):\n",
    "    vader = SentimentIntensityAnalyzer()\n",
    "\n",
    "    parsed_and_scored_news = pd.DataFrame(parsed_news, columns = ['ticker', 'date', 'time', 'headline'])\n",
    "\n",
    "    scores = parsed_and_scored_news['headline'].apply(vader.polarity_scores).tolist()\n",
    "    df_scores = pd.DataFrame(scores)\n",
    "\n",
    "    parsed_and_scored_news = parsed_and_scored_news.join(df_scores, rsuffix='_right')\n",
    "    #parsed_and_scored_news['date'] = pd.to_datetime(parsed_and_scored_news.date).dt.date\n",
    "\n",
    "    return parsed_and_scored_news\n",
    "\n",
    "def Load_Sentiment(parsed_and_scored_news, conn, cur):\n",
    "    # Combine date and time columns and prep for db\n",
    "    parsed_and_scored_news['timestamp'] = pd.to_datetime(parsed_and_scored_news['date'] + ' ' + parsed_and_scored_news['time'])\n",
    "    del parsed_and_scored_news['date'], parsed_and_scored_news['time'], parsed_and_scored_news['neg'],  parsed_and_scored_news['neu'],  parsed_and_scored_news['pos'] \n",
    "\n",
    "    # Add qualitative scale to scores?\n",
    "    score_name = {'very positive', 'positive', 'neutral', 'negative', 'very negative'}\n",
    "\n",
    "    insert = [list(row) for row in parsed_and_scored_news.itertuples(index=False)]\n",
    "\n",
    "    SQL_sentiment_insert= \"\"\" INSERT INTO public.sentiment(ticker, headline, score, timestamp) \n",
    "        VALUES (%s, %s, %s, %s) ON CONFLICT DO NOTHING\"\"\"\n",
    "    cur.executemany(SQL_sentiment_insert, insert)\n",
    "    conn.commit()\n",
    "\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
